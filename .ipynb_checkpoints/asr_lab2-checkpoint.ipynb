{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d0eabe",
   "metadata": {},
   "source": [
    "# Языковые модели\n",
    "\n",
    "Языковые модели играют важную роль в системах распознавания речи, помогая создавать более грамотные и лексически корректные тексты. В данной работе мы будем изучать нграмные языковые модели, которые позволяют довольно легко оценить вероятность и правдоподобность текста.\n",
    "\n",
    "В нграмной языковой модели, нграм - это последовательность из n слов в тексте. Например, в предложении \"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\", биграмами будут \"по-моему мы\", \"мы сэкономим\", \"сэкономим уйму\" итд. Языковые модели оценивают вероятность появления последовательности слов, исходя из статистики появления каждого из нграм в обучающей выборке.\n",
    "\n",
    "Порядком (order) нграм языковой модели называют максимальную длину нграм, которую учитывает модель. \n",
    "\n",
    "Практическая работа разделена на 2 части: \n",
    "1. Построение нграмой языковой модели - основная часть, 10 баллов\n",
    "1. Предсказание с помощью языковой модели - дополнительная часть, 6 балла\n",
    "\n",
    "\n",
    "\n",
    "Полезные сслыки:\n",
    "* arpa формат - https://cmusphinx.github.io/wiki/arpaformat/\n",
    "* обучающие материалы - https://pages.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture13/lecture13_ngrams_with_SRILM.pdf\n",
    "* обучающие материалы.2 - https://cjlise.github.io/machine-learning/N-Gram-Language-Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bd5c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1c1d7",
   "metadata": {},
   "source": [
    "# 1. Построение нграмной языковой модели. (10 баллов)\n",
    "\n",
    "\n",
    "Вероятность текста с помощью нграмной языковой модели можно вычислить по формуле: \n",
    "$$ P(w_1, w_2, .., w_n) = {\\prod{{P_{i=0}^{n}(w_i| w_{i-order}, .., w_{i-1})}}} $$\n",
    "\n",
    "В простом виде, при обучении нграмной языковой модели, чтобы рассчитать условную вероятность каждой нграмы, используется формула, основанная на количестве появлений нграмы в обучающей выборке. Формула выглядит следующим образом:\n",
    "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i})} \\over {count(w_{i-order},..., w_{i-1})}} $$\n",
    "\n",
    "Поскольку униграмы не содержат в себе какого-дибо контекста, вероятность униграмы можно посчитать поделив кол-во этой слова на общее количество слов в обучающей выборке. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5837fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в первую очередь нам понадобится подсчитать статистику по обучающей выборке \n",
    "def count_ngrams(train_text: List[str], order=3, bos=True, eos=True) -> Dict[Tuple[str], int]:\n",
    "    ngrams = defaultdict(int)\n",
    "    for sentence in train_text:\n",
    "        words = sentence.split()\n",
    "        \n",
    "        # добавляем маркеры начала и конца предложения, если нужно\n",
    "        if bos:\n",
    "            words = ['<s>'] + words\n",
    "        if eos:\n",
    "            words = words + ['</s>']\n",
    "        \n",
    "        # итерируем по каждому порядку n-грамм от 1 до order\n",
    "        for n in range(1, order + 1):\n",
    "            for i in range(len(words) - n + 1):\n",
    "                ngram = tuple(words[i:i + n])\n",
    "                ngrams[ngram] += 1\n",
    "    return dict(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd69d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1a passed\n"
     ]
    }
   ],
   "source": [
    "def test_count_ngrams():\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=True, eos=True) == {\n",
    "        ('<s>',): 1, \n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1, \n",
    "        ('</s>',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=True) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1, \n",
    "        ('</s>',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=False) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=2, bos=False, eos=False) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1,\n",
    "        ('привет', 'привет'): 1,\n",
    "        ('привет', 'как'): 1,\n",
    "        ('как', 'дела'): 1\n",
    "    }    \n",
    "    assert count_ngrams(['привет ' * 6], order=2, bos=False, eos=False) == {\n",
    "        ('привет',): 6, \n",
    "        ('привет', 'привет'): 5\n",
    "    }\n",
    "    result = count_ngrams(['практическое сентября',\n",
    "                           'второе практическое занятие пройдет в офлайне 32 сентября в 12 часов 32 минуты',\n",
    "                           'в офлайне в 32 12'], order=5)\n",
    "    assert result[('<s>',)] == 3\n",
    "    assert result[('32',)] == 3\n",
    "    assert result[('<s>', 'в', 'офлайне', 'в', '32')] == 1\n",
    "    assert result[('офлайне', 'в', '32', '12', '</s>')] == 1\n",
    "    print('Test 1a passed')\n",
    "    \n",
    "    \n",
    "test_count_ngrams()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e1865",
   "metadata": {},
   "source": [
    "\n",
    "Простой подход к вычислению вероятностей через количество нграм имеет существенный недостаток. Если в тексте встретится нграмма, которой не было в обучающей выборке, то вероятность всего текста будет равна нулю. \n",
    "\n",
    "Чтобы избежать данного недостатка, вводится специальное сглаживание - add-k сглаживание ([Additive, Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)). Данная техника позволяет учитывать нграмы, не встретившиеся в обучающей выборке, и при этом не делает вероятность текста равной нулю.\n",
    "\n",
    "Формула сглаживания Лапласа выглядит следующим образом:\n",
    "\n",
    "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i}) + k} \\over {count(w_{i-order},..., w_{i-1}) + k*V}} $$\n",
    "\n",
    "Здесь V - количество слов в словаре, а k - гиперпараметр, который контролирует меру сглаживания. Как правило, значение k выбирается экспериментально, чтобы найти оптимальный баланс между учетом редких нграм и сохранением вероятности для часто встречающихся нграм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cafb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция подсчета вероятности через количество со сглаживанием Лапласа\n",
    "def calculate_ngram_prob(ngram: Tuple[str], counts: Dict[Tuple[str], int], V=None, k=0) -> float:\n",
    "    # подсчитывет ngram со сглаживанием Лапласа\n",
    "    n = len(ngram)\n",
    "    \n",
    "    # кол-во n-грамм\n",
    "    ngram_count = counts.get(ngram, 0)\n",
    "    \n",
    "    # если V не задан считаем уникальные слова\n",
    "    if V is None:\n",
    "        V = len({token for ngram_tuple in counts.keys() for token in ngram_tuple})\n",
    "    \n",
    "    # если это униграмма то знаменатель это общее количество слов\n",
    "    if n == 1:\n",
    "        total_word_count = sum(count for ngram_tuple, count in counts.items() if len(ngram_tuple) == 1)\n",
    "        denominator = total_word_count + k * V\n",
    "    else:\n",
    "        ngram_prefix = ngram[:-1]\n",
    "        prefix_count = counts.get(ngram_prefix, 0)\n",
    "        denominator = prefix_count + k * V\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    prob = (ngram_count + k) / denominator\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b25d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.b passed\n"
     ]
    }
   ],
   "source": [
    "def test_calculate_ngram_prob():\n",
    "    counts = count_ngrams(['практическое сентября',\n",
    "                           'второе практическое занятие в офлайне 32 сентября в 12 часов 32 минуты',\n",
    "                           'в офлайне в 32 12'], order=4)\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts) == 0.5\n",
    "    assert calculate_ngram_prob(('в', ), counts) == 4/25\n",
    "    assert calculate_ngram_prob(('в', ), counts, k=0.5) == (4+0.5)/(25+0.5*12)\n",
    "    assert calculate_ngram_prob(('в', 'офлайне', 'в', '32'), counts) == 1.0\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=1) == 0.1875\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
    "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=0) == 0.0\n",
    "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=1) == 0.0625\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
    "\n",
    "    print(\"Test 1.b passed\")\n",
    "    \n",
    "\n",
    "test_calculate_ngram_prob()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da494bf0",
   "metadata": {},
   "source": [
    "Основной метрикой язковых моделей является перплексия. \n",
    "\n",
    "Перплексия  — безразмерная величина, мера того, насколько хорошо распределение вероятностей предсказывает выборку. Низкий показатель перплексии указывает на то, что распределение вероятности хорошо предсказывает выборку.\n",
    "\n",
    "$$ ppl = {P(w_1, w_2 ,..., w_N)^{- {1} \\over {N}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4bd1f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramLM:\n",
    "    def __init__(self, order=3, bos=True, eos=True, k=1, predefined_vocab=None):\n",
    "        self.order = order\n",
    "        self.eos = eos\n",
    "        self.bos = bos\n",
    "        self.k = k\n",
    "        self.vocab = predefined_vocab\n",
    "        self.ngrams_count = None\n",
    "\n",
    "    @property\n",
    "    def V(self) -> int:\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def fit(self, train_text: List[str]) -> None:\n",
    "        # используем функцию для подсчета n-грамм и их кол-ва\n",
    "        self.ngrams_count = count_ngrams(train_text, order=self.order, bos=self.bos, eos=self.eos)\n",
    "        self.vocab = set(word for ngram in self.ngrams_count.keys() for word in ngram)\n",
    "\n",
    "    def predict_ngram_log_proba(self, ngram: Tuple[str]) -> float:\n",
    "        # вычисляем вероятность для заданной n-граммы\n",
    "        prob = calculate_ngram_prob(ngram, self.ngrams_count, k=self.k)\n",
    "        return np.log(prob) if prob > 0 else float('-inf')\n",
    "\n",
    "    def predict_log_proba(self, words: List[str]) -> float:\n",
    "        if self.bos:\n",
    "            words = ['<s>'] + words\n",
    "        if self.eos:\n",
    "            words += ['</s>']\n",
    "\n",
    "        logprob = 0\n",
    "        # убираем пустые строки\n",
    "        words = [word for word in words if word.strip()]\n",
    "\n",
    "        for i in range(len(words)):\n",
    "            # определяем диапазон для n-граммы\n",
    "            start_index = max(0, i + 1 - self.order)\n",
    "            ngram = tuple(words[start_index:i + 1])  # Создаем n-грамму\n",
    "\n",
    "            # добавляем логарифм вероятности n-граммы к общему логарифму вероятности\n",
    "            logprob += self.predict_ngram_log_proba(ngram)\n",
    "\n",
    "        return logprob\n",
    "\n",
    "    def ppl(self, text: List[str]) -> float:\n",
    "        total_logprob = 0\n",
    "        total_words = 0\n",
    "\n",
    "        # итерируемся по строкам в тексте\n",
    "        for line in text:\n",
    "            words = line.split()  # разбиваем строку на слова\n",
    "            line_logprob = self.predict_log_proba(words)  # вычисляем логарифм вероятности строки\n",
    "            total_logprob += line_logprob\n",
    "\n",
    "            # общее количество слов с учетом токенов начала и конца\n",
    "            total_words += len(words) + (1 if self.bos else 0) + (1 if self.eos else 0)\n",
    "        # рассчитываем перплексию\n",
    "        perplexity = np.exp(-total_logprob / total_words) if total_words > 0 else float('inf')\n",
    "        return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bb0bfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lm():\n",
    "    train_data = [\"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\",\n",
    "                  \"если я сойду с ума прямо сейчас по-моему мы сэкономим уйму времени\",\n",
    "                  \"мы сэкономим уйму времени если я сейчас сойду с ума по-моему\"]\n",
    "    global lm\n",
    "    lm = NgramLM(order=2)\n",
    "    lm.fit(train_data)\n",
    "    assert lm.V == 14\n",
    "    assert np.isclose(lm.predict_log_proba(['мы']), lm.predict_log_proba([\"если\"]))\n",
    "    assert lm.predict_log_proba([\"по-моему\"]) > lm.predict_log_proba([\"если\"]) \n",
    "    \n",
    "    gt = ((3+1)/(41 + 14) * 1/(3+14))**(-1/2)\n",
    "    ppl = lm.ppl([''])\n",
    "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
    "    \n",
    "    gt = ((3+1)/(41 + 14) * 1/(3+14) * 1/(14)) ** (-1/3)\n",
    "    ppl = lm.ppl(['ЧТО'])\n",
    "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
    "    \n",
    "    test_data = [\"по-моему если я прямо сейчас сойду с ума мы сэкономим уйму времени\"]\n",
    "    ppl = lm.ppl(test_data)\n",
    "    assert round(ppl, 2) == 7.33, f\"{ppl}\"\n",
    "test_lm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafa0a2",
   "metadata": {},
   "source": [
    "# 2. Предсказания с помощью языковой модели (6 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4846b",
   "metadata": {},
   "source": [
    "Попробуйте обучить ngram языковую модель на нескольких стихотворениях. Не забудьте трансформировать стихотворение в удобный для ngram модели формат (как сделать так, чтобы модель моделировала рифму?). \n",
    "Попробуйте сгенерировать продолжение для стихотворения с помощью такой языковой модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6ae32bb0-621a-4b05-98ab-da6c100e1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированное продолжение:\n",
      "пустынных волн идет морям\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[str]:\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    lines = text.splitlines()  \n",
    "    return [line for line in lines if line]  \n",
    "\n",
    "def predict_next_word(lm: NgramLM, prefix: List[str], topk=4) -> List[Tuple[str, float]]:\n",
    "    candidates = {}\n",
    "\n",
    "    for word in lm.vocab:\n",
    "        ngram = tuple(prefix[-(lm.order - 1):] + [word])\n",
    "        log_prob = lm.predict_ngram_log_proba(ngram)\n",
    "        if log_prob != float('-inf'):\n",
    "            candidates[word] = log_prob\n",
    "\n",
    "    sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_candidates[:topk]\n",
    "\n",
    "def weighted_random_choice(predictions: List[Tuple[str, float]]) -> str:\n",
    "    if not predictions:\n",
    "        return None  # Возвращаем None, если предсказаний нет\n",
    "\n",
    "    words, probabilities = zip(*predictions)\n",
    "    probabilities = np.exp(probabilities)  # Преобразование логарифмических вероятностей\n",
    "    probabilities /= probabilities.sum()  # Нормализация\n",
    "    return np.random.choice(words, p=probabilities)\n",
    "\n",
    "def rhymes_with(word1: str, word2: str) -> bool:\n",
    "    return word1[-5:] == word2[-5:]  # проверка на рифму\n",
    "\n",
    "def generate_poem_continuation_with_rhyme(lm: NgramLM, start_words: List[str], max_length=20) -> List[str]:\n",
    "    current_prefix = start_words.copy()\n",
    "    generated_words = []\n",
    "    last_word = current_prefix[-1] if current_prefix else \"\"\n",
    "    seen_words = set()  # храним уже сгенерированные слова\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        predictions = predict_next_word(lm, current_prefix, topk=10)\n",
    "\n",
    "        # фильтруем предсказания по рифме\n",
    "        filtered_predictions = [(word, prob) for word, prob in predictions if rhymes_with(word, last_word) and word not in seen_words]\n",
    "\n",
    "        # если нет рифм, берем все предсказания\n",
    "        if not filtered_predictions:\n",
    "            filtered_predictions = [(word, prob) for word, prob in predictions if word not in seen_words]\n",
    "\n",
    "        # если нет доступных слов, выходим из цикла\n",
    "        if not filtered_predictions:\n",
    "            break\n",
    "        \n",
    "        # случайным образом выбираем одно из подходящих предсказаний\n",
    "        next_word = weighted_random_choice(filtered_predictions)\n",
    "        if next_word is None:\n",
    "            break  # если нет слов для выбора, выходим из цикла\n",
    "\n",
    "        generated_words.append(next_word)\n",
    "        current_prefix.append(next_word)\n",
    "        last_word = next_word  # обновляем последнее слово\n",
    "        seen_words.add(next_word)  # добавляем слово в использованные\n",
    "\n",
    "        if len(current_prefix) > lm.order - 1:\n",
    "            current_prefix.pop(0)\n",
    "\n",
    "    return generated_words\n",
    "\n",
    "preprocessed_poem = preprocess_text(poem)\n",
    "\n",
    "model = NgramLM(order=3, k=1, bos=True, eos=True)\n",
    "model.fit(preprocessed_poem)\n",
    "\n",
    "start_words = [\"на\", \"берегу\"]\n",
    "generated_continuation = generate_poem_continuation_with_rhyme(model, start_words, max_length=4)\n",
    "\n",
    "print(\"Сгенерированное продолжение:\")\n",
    "print(\" \".join(generated_continuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3e260e0c-0cf0-41c1-9d40-fc1da2e93bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"На берегу пустынных волн\n",
    "Стоял он, дум великих полн,\n",
    "И вдаль глядел. Пред ним широко\n",
    "Река неслася; бедный чёлн\n",
    "По ней стремился одиноко.\n",
    "По мшистым, топким берегам\n",
    "Чернели избы здесь и там,\n",
    "Приют убогого чухонца;\n",
    "И лес, неведомый лучам\n",
    "В тумане спрятанного солнца,\n",
    "Кругом шумел.\n",
    "И думал он:\n",
    "Отсель грозить мы будем шведу,\n",
    "Здесь будет город заложен\n",
    "На зло надменному соседу.\n",
    "Природой здесь нам суждено\n",
    "В Европу прорубить окно,\n",
    "Ногою твердой стать при море.\n",
    "Сюда по новым им волнам\n",
    "Все флаги в гости будут к нам,\n",
    "И запируем на просторе.\n",
    "Прошло сто лет, и юный град,\n",
    "Полнощных стран краса и диво,\n",
    "Из тьмы лесов, из топи блат\n",
    "Вознесся пышно, горделиво;\n",
    "Где прежде финский рыболов,\n",
    "Печальный пасынок природы,\n",
    "Один у низких берегов\n",
    "Бросал в неведомые воды\n",
    "Свой ветхой невод, ныне там\n",
    "По оживленным берегам\n",
    "Громады стройные теснятся\n",
    "Дворцов и башен; корабли\n",
    "Толпой со всех концов земли\n",
    "К богатым пристаням стремятся;\n",
    "В гранит оделася Нева;\n",
    "Мосты повисли над водами;\n",
    "Темно-зелеными садами\n",
    "Ее покрылись острова,\n",
    "И перед младшею столицей\n",
    "Померкла старая Москва,\n",
    "Как перед новою царицей\n",
    "Порфироносная вдова.\n",
    "Люблю тебя, Петра творенье,\n",
    "Люблю твой строгий, стройный вид,\n",
    "Невы державное теченье,\n",
    "Береговой ее гранит,\n",
    "Твоих оград узор чугунный,\n",
    "Твоих задумчивых ночей\n",
    "Прозрачный сумрак, блеск безлунный,\n",
    "Когда я в комнате моей\n",
    "Пишу, читаю без лампады,\n",
    "И ясны спящие громады\n",
    "Пустынных улиц, и светла\n",
    "Адмиралтейская игла,\n",
    "И, не пуская тьму ночную\n",
    "На золотые небеса,\n",
    "Одна заря сменить другую\n",
    "Спешит, дав ночи полчаса.\n",
    "Люблю зимы твоей жестокой\n",
    "Недвижный воздух и мороз,\n",
    "Бег санок вдоль Невы широкой,\n",
    "Девичьи лица ярче роз,\n",
    "И блеск, и шум, и говор балов,\n",
    "А в час пирушки холостой\n",
    "Шипенье пенистых бокалов\n",
    "И пунша пламень голубой.\n",
    "Люблю воинственную живость\n",
    "Потешных Марсовых полей,\n",
    "Пехотных ратей и коней\n",
    "Однообразную красивость,\n",
    "В их стройно зыблемом строю\n",
    "Лоскутья сих знамен победных,\n",
    "Сиянье шапок этих медных,\n",
    "Насквозь простреленных в бою.\n",
    "Люблю, военная столица,\n",
    "Твоей твердыни дым и гром,\n",
    "Когда полнощная царица\n",
    "Дарует сына в царской дом,\n",
    "Или победу над врагом\n",
    "Россия снова торжествует,\n",
    "Или, взломав свой синий лед,\n",
    "Нева к морям его несет\n",
    "И, чуя вешни дни, ликует.\n",
    "Красуйся, град Петров, и стой\n",
    "Неколебимо как Россия,\n",
    "Да умирится же с тобой\n",
    "И побежденная стихия;\n",
    "Вражду и плен старинный свой\n",
    "Пусть волны финские забудут\n",
    "И тщетной злобою не будут\n",
    "Тревожить вечный сон Петра!\n",
    "Была ужасная пора,\n",
    "Об ней свежо воспоминанье…\n",
    "Об ней, друзья мои, для вас\n",
    "Начну свое повествованье.\n",
    "Печален будет мой рассказ.\n",
    "\n",
    "Часть первая\n",
    "Над омраченным Петроградом\n",
    "Дышал ноябрь осенним хладом.\n",
    "Плеская шумною волной\n",
    "В края своей ограды стройной,\n",
    "Нева металась, как больной\n",
    "В своей постеле беспокойной.\n",
    "Уж было поздно и темно;\n",
    "Сердито бился дождь в окно,\n",
    "И ветер дул, печально воя.\n",
    "В то время из гостей домой\n",
    "Пришел Евгений молодой…\n",
    "Мы будем нашего героя\n",
    "Звать этим именем. Оно\n",
    "Звучит приятно; с ним давно\n",
    "Мое перо к тому же дружно.\n",
    "Прозванья нам его не нужно,\n",
    "Хотя в минувши времена\n",
    "Оно, быть может, и блистало\n",
    "И под пером Карамзина\n",
    "В родных преданьях прозвучало;\n",
    "Но ныне светом и молвой\n",
    "Оно забыто. Наш герой\n",
    "Живет в Коломне; где-то служит,\n",
    "Дичится знатных и не тужит\n",
    "Ни о почиющей родне,\n",
    "Ни о забытой старине.\n",
    "Итак, домой пришед, Евгений\n",
    "Стряхнул шинель, разделся, лег.\n",
    "Но долго он заснуть не мог\n",
    "В волненье разных размышлений.\n",
    "О чем же думал он? о том,\n",
    "Что был он беден, что трудом\n",
    "Он должен был себе доставить\n",
    "И независимость и честь;\n",
    "Что мог бы бог ему прибавить\n",
    "Ума и денег. Что ведь есть\n",
    "Такие праздные счастливцы,\n",
    "Ума недальнего, ленивцы,\n",
    "Которым жизнь куда легка!\n",
    "Что служит он всего два года;\n",
    "Он также думал, что погода\n",
    "Не унималась; что река\n",
    "Всё прибывала; что едва ли\n",
    "С Невы мостов уже не сняли\n",
    "И что с Парашей будет он\n",
    "Дни на два, на три разлучен.\n",
    "Евгений тут вздохнул сердечно\n",
    "И размечтался, как поэт:\n",
    "«Жениться? Мне? зачем же нет?\n",
    "Оно и тяжело, конечно;\n",
    "Но что ж, я молод и здоров,\n",
    "Трудиться день и ночь готов;\n",
    "Уж кое-как себе устрою\n",
    "Приют смиренный и простой\n",
    "И в нем Парашу успокою.\n",
    "Пройдет, быть может, год-другой —\n",
    "Местечко получу, Параше\n",
    "Препоручу семейство наше\n",
    "И воспитание ребят…\n",
    "И станем жить, и так до гроба\n",
    "Рука с рукой дойдем мы оба,\n",
    "И внуки нас похоронят…»\n",
    "Так он мечтал. И грустно было\n",
    "Ему в ту ночь, и он желал,\n",
    "Чтоб ветер выл не так уныло\n",
    "И чтобы дождь в окно стучал\n",
    "Не так сердито…\n",
    "Сонны очи\n",
    "Он наконец закрыл. И вот\n",
    "Редеет мгла ненастной ночи\n",
    "И бледный день уж настает…\n",
    "Ужасный день!\n",
    "Нева всю ночь\n",
    "Рвалася к морю против бури,\n",
    "Не одолев их буйной дури…\n",
    "И спорить стало ей невмочь…\n",
    "Поутру над ее брегами\n",
    "Теснился кучами народ,\n",
    "Любуясь брызгами, горами\n",
    "И пеной разъяренных вод.\n",
    "Но силой ветров от залива\n",
    "Перегражденная Нева\n",
    "Обратно шла, гневна, бурлива,\n",
    "И затопляла острова,\n",
    "Погода пуще свирепела,\n",
    "Нева вздувалась и ревела,\n",
    "Котлом клокоча и клубясь,\n",
    "И вдруг, как зверь остервенясь,\n",
    "На город кинулась. Пред нею\n",
    "Всё побежало, всё вокруг\n",
    "Вдруг опустело — воды вдруг\n",
    "Втекли в подземные подвалы,\n",
    "К решеткам хлынули каналы,\n",
    "И всплыл Петрополь как тритон,\n",
    "По пояс в воду погружен.\n",
    "Осада! приступ! злые волны,\n",
    "Как воры, лезут в окна. Челны\n",
    "С разбега стекла бьют кормой.\n",
    "Лотки под мокрой пеленой,\n",
    "Обломки хижин, бревны, кровли,\n",
    "Товар запасливой торговли,\n",
    "Пожитки бледной нищеты,\n",
    "Грозой снесенные мосты,\n",
    "Гроба с размытого кладбища\n",
    "Плывут по улицам!\n",
    "Народ\n",
    "Зрит божий гнев и казни ждет.\n",
    "Увы! всё гибнет: кров и пища!\n",
    "Где будет взять?\n",
    "В тот грозный год\n",
    "Покойный царь еще Россией\n",
    "Со славой правил. На балкон,\n",
    "Печален, смутен, вышел он\n",
    "И молвил: «С божией стихией\n",
    "Царям не совладеть». Он сел\n",
    "И в думе скорбными очами\n",
    "На злое бедствие глядел.\n",
    "Стояли стогны озерами,\n",
    "И в них широкими реками\n",
    "Вливались улицы. Дворец\n",
    "Казался островом печальным.\n",
    "Царь молвил — из конца в конец,\n",
    "По ближним улицам и дальным\n",
    "В опасный путь средь бурных вод\n",
    "Его пустились генералы\n",
    "Спасать и страхом обуялый\n",
    "И дома тонущий народ.\n",
    "Тогда, на площади Петровой,\n",
    "Где дом в углу вознесся новый,\n",
    "Где над возвышенным крыльцом\n",
    "С подъятой лапой, как живые,\n",
    "Стоят два льва сторожевые,\n",
    "На звере мраморном верхом,\n",
    "Без шляпы, руки сжав крестом,\n",
    "Сидел недвижный, страшно бледный\n",
    "Евгений. Он страшился, бедный,\n",
    "Не за себя. Он не слыхал,\n",
    "Как подымался жадный вал,\n",
    "Ему подошвы подмывая,\n",
    "Как дождь ему в лицо хлестал,\n",
    "Как ветер, буйно завывая,\n",
    "С него и шляпу вдруг сорвал.\n",
    "Его отчаянные взоры\n",
    "На край один наведены\n",
    "Недвижно были. Словно горы,\n",
    "Из возмущенной глубины\n",
    "Вставали волны там и злились,\n",
    "Там буря выла, там носились\n",
    "Обломки… Боже, боже! там —\n",
    "Увы! близехонько к волнам,\n",
    "Почти у самого залива —\n",
    "Забор некрашеный, да ива\n",
    "И ветхий домик: там оне,\n",
    "Вдова и дочь, его Параша,\n",
    "Его мечта… Или во сне\n",
    "Он это видит? иль вся наша\n",
    "И жизнь ничто, как сон пустой,\n",
    "Насмешка неба над землей?\n",
    "И он, как будто околдован,\n",
    "Как будто к мрамору прикован,\n",
    "Сойти не может! Вкруг него\n",
    "Вода и больше ничего!\n",
    "И, обращен к нему спиною,\n",
    "В неколебимой вышине,\n",
    "Над возмущенною Невою\n",
    "Стоит с простертою рукою\n",
    "Кумир на бронзовом коне.\n",
    "\n",
    "Часть вторая\n",
    "Но вот, насытясь разрушеньем\n",
    "И наглым буйством утомясь,\n",
    "Нева обратно повлеклась,\n",
    "Своим любуясь возмущеньем\n",
    "И покидая с небреженьем\n",
    "Свою добычу. Так злодей,\n",
    "С свирепой шайкою своей\n",
    "В село ворвавшись, ломит, режет,\n",
    "Крушит и грабит; вопли, скрежет,\n",
    "Насилье, брань, тревога, вой!..\n",
    "И, грабежом отягощенны,\n",
    "Боясь погони, утомленны,\n",
    "Спешат разбойники домой,\n",
    "Добычу на пути роняя.\n",
    "Вода сбыла, и мостовая\n",
    "Открылась, и Евгений мой\n",
    "Спешит, душою замирая,\n",
    "В надежде, страхе и тоске\n",
    "К едва смирившейся реке.\n",
    "Но, торжеством победы полны,\n",
    "Еще кипели злобно волны,\n",
    "Как бы под ними тлел огонь,\n",
    "Еще их пена покрывала,\n",
    "И тяжело Нева дышала,\n",
    "Как с битвы прибежавший конь.\n",
    "Евгений смотрит: видит лодку;\n",
    "Он к ней бежит как на находку;\n",
    "Он перевозчика зовет —\n",
    "И перевозчик беззаботный\n",
    "Его за гривенник охотно\n",
    "Чрез волны страшные везет.\n",
    "И долго с бурными волнами\n",
    "Боролся опытный гребец,\n",
    "И скрыться вглубь меж их рядами\n",
    "Всечасно с дерзкими пловцами\n",
    "Готов был челн — и наконец\n",
    "Достиг он берега.\n",
    "Несчастный\n",
    "Знакомой улицей бежит\n",
    "В места знакомые. Глядит,\n",
    "Узнать не может. Вид ужасный!\n",
    "Всё перед ним завалено;\n",
    "Что сброшено, что снесено;\n",
    "Скривились домики, другие\n",
    "Совсем обрушились, иные\n",
    "Волнами сдвинуты; кругом,\n",
    "Как будто в поле боевом,\n",
    "Тела валяются. Евгений\n",
    "Стремглав, не помня ничего,\n",
    "Изнемогая от мучений,\n",
    "Бежит туда, где ждет его\n",
    "Судьба с неведомым известьем,\n",
    "Как с запечатанным письмом.\n",
    "И вот бежит уж он предместьем,\n",
    "И вот залив, и близок дом…\n",
    "Что ж это?..\n",
    "Он остановился.\n",
    "Пошел назад и воротился.\n",
    "Глядит… идет… еще глядит.\n",
    "Вот место, где их дом стоит;\n",
    "Вот ива. Были здесь вороты —\n",
    "Снесло их, видно. Где же дом?\n",
    "И, полон сумрачной заботы,\n",
    "Все ходит, ходит он кругом,\n",
    "Толкует громко сам с собою —\n",
    "И вдруг, ударя в лоб рукою,\n",
    "Захохотал.\n",
    "Ночная мгла\n",
    "На город трепетный сошла;\n",
    "Но долго жители не спали\n",
    "И меж собою толковали\n",
    "О дне минувшем.\n",
    "Утра луч\n",
    "Из-за усталых, бледных туч\n",
    "Блеснул над тихою столицей\n",
    "И не нашел уже следов\n",
    "Беды вчерашней; багряницей\n",
    "Уже прикрыто было зло.\n",
    "В порядок прежний всё вошло.\n",
    "Уже по улицам свободным\n",
    "С своим бесчувствием холодным\n",
    "Ходил народ. Чиновный люд,\n",
    "Покинув свой ночной приют,\n",
    "На службу шел. Торгаш отважный,\n",
    "Не унывая, открывал\n",
    "Невой ограбленный подвал,\n",
    "Сбираясь свой убыток важный\n",
    "На ближнем выместить. С дворов\n",
    "Свозили лодки.\n",
    "Граф Хвостов,\n",
    "Поэт, любимый небесами,\n",
    "Уж пел бессмертными стихами\n",
    "Несчастье невских берегов.\n",
    "Но бедный, бедный мой Евгений …\n",
    "Увы! его смятенный ум\n",
    "Против ужасных потрясений\n",
    "Не устоял. Мятежный шум\n",
    "Невы и ветров раздавался\n",
    "В его ушах. Ужасных дум\n",
    "Безмолвно полон, он скитался.\n",
    "Его терзал какой-то сон.\n",
    "Прошла неделя, месяц — он\n",
    "К себе домой не возвращался.\n",
    "Его пустынный уголок\n",
    "Отдал внаймы, как вышел срок,\n",
    "Хозяин бедному поэту.\n",
    "Евгений за своим добром\n",
    "Не приходил. Он скоро свету\n",
    "Стал чужд. Весь день бродил пешком,\n",
    "А спал на пристани; питался\n",
    "В окошко поданным куском.\n",
    "Одежда ветхая на нем\n",
    "Рвалась и тлела. Злые дети\n",
    "Бросали камни вслед ему.\n",
    "Нередко кучерские плети\n",
    "Его стегали, потому\n",
    "Что он не разбирал дороги\n",
    "Уж никогда; казалось — он\n",
    "Не примечал. Он оглушен\n",
    "Был шумом внутренней тревоги.\n",
    "И так он свой несчастный век\n",
    "Влачил, ни зверь ни человек,\n",
    "Ни то ни сё, ни житель света,\n",
    "Ни призрак мертвый…\n",
    "Раз он спал\n",
    "У невской пристани. Дни лета\n",
    "Клонились к осени. Дышал\n",
    "Ненастный ветер. Мрачный вал\n",
    "Плескал на пристань, ропща пени\n",
    "И бьясь об гладкие ступени,\n",
    "Как челобитчик у дверей\n",
    "Ему не внемлющих судей.\n",
    "Бедняк проснулся. Мрачно было:\n",
    "Дождь капал, ветер выл уныло,\n",
    "И с ним вдали, во тьме ночной\n",
    "Перекликался часовой…\n",
    "Вскочил Евгений; вспомнил живо\n",
    "Он прошлый ужас; торопливо\n",
    "Он встал; пошел бродить, и вдруг\n",
    "Остановился — и вокруг\n",
    "Тихонько стал водить очами\n",
    "С боязнью дикой на лице.\n",
    "Он очутился под столбами\n",
    "Большого дома. На крыльце\n",
    "С подъятой лапой, как живые,\n",
    "Стояли львы сторожевые,\n",
    "И прямо в темной вышине\n",
    "Над огражденною скалою\n",
    "Кумир с простертою рукою\n",
    "Сидел на бронзовом коне.\n",
    "Евгений вздрогнул. Прояснились\n",
    "В нем страшно мысли. Он узнал\n",
    "И место, где потоп играл,\n",
    "Где волны хищные толпились,\n",
    "Бунтуя злобно вкруг него,\n",
    "И львов, и площадь, и того,\n",
    "Кто неподвижно возвышался\n",
    "Во мраке медною главой,\n",
    "Того, чьей волей роковой\n",
    "Под морем город основался…\n",
    "Ужасен он в окрестной мгле!\n",
    "Какая дума на челе!\n",
    "Какая сила в нем сокрыта!\n",
    "А в сем коне какой огонь!\n",
    "Куда ты скачешь, гордый конь,\n",
    "И где опустишь ты копыта?\n",
    "О мощный властелин судьбы!\n",
    "Не так ли ты над самой бездной\n",
    "На высоте, уздой железной\n",
    "Россию поднял на дыбы?\n",
    "Кругом подножия кумира\n",
    "Безумец бедный обошел\n",
    "И взоры дикие навел\n",
    "На лик державца полумира.\n",
    "Стеснилась грудь его. Чело\n",
    "К решетке хладной прилегло,\n",
    "Глаза подернулись туманом,\n",
    "По сердцу пламень пробежал,\n",
    "Вскипела кровь. Он мрачен стал\n",
    "Пред горделивым истуканом\n",
    "И, зубы стиснув, пальцы сжав,\n",
    "Как обуянный силой черной,\n",
    "«Добро, строитель чудотворный! —\n",
    "Шепнул он, злобно задрожав, —\n",
    "Ужо тебе!..» И вдруг стремглав\n",
    "Бежать пустился. Показалось\n",
    "Ему, что грозного царя,\n",
    "Мгновенно гневом возгоря,\n",
    "Лицо тихонько обращалось…\n",
    "И он по площади пустой\n",
    "Бежит и слышит за собой —\n",
    "Как будто грома грохотанье —\n",
    "Тяжело-звонкое скаканье\n",
    "По потрясенной мостовой.\n",
    "И, озарен луною бледной,\n",
    "Простерши руку в вышине,\n",
    "За ним несется Всадник Медный\n",
    "На звонко-скачущем коне;\n",
    "И во всю ночь безумец бедный,\n",
    "Куда стопы ни обращал,\n",
    "За ним повсюду Всадник Медный\n",
    "С тяжелым топотом скакал.\n",
    "И с той поры, когда случалось\n",
    "Идти той площадью ему,\n",
    "В его лице изображалось\n",
    "Смятенье. К сердцу своему\n",
    "Он прижимал поспешно руку,\n",
    "Как бы его смиряя муку,\n",
    "Картуз изношенный сымал,\n",
    "Смущенных глаз не подымал\n",
    "И шел сторонкой.\n",
    "Остров малый\n",
    "На взморье виден. Иногда\n",
    "Причалит с неводом туда\n",
    "Рыбак на ловле запоздалый\n",
    "И бедный ужин свой варит,\n",
    "Или чиновник посетит,\n",
    "Гуляя в лодке в воскресенье,\n",
    "Пустынный остров. Не взросло\n",
    "Там ни былинки. Наводненье\n",
    "Туда, играя, занесло\n",
    "Домишко ветхой. Над водою\n",
    "Остался он как черный куст.\n",
    "Его прошедшею весною\n",
    "Свезли на барке. Был он пуст\n",
    "И весь разрушен. У порога\n",
    "Нашли безумца моего,\n",
    "И тут же хладный труп его\n",
    "Похоронили ради бога.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
